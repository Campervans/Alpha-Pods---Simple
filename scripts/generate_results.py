#!/usr/bin/env python3
# CVaR index backtest runner - generates all the deliverables

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import os
import warnings
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
np.random.seed(42)

def download_sp100_data():
    # grab sp100 stocks for backtest
    tickers = [
        'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'JPM',
        'JNJ', 'V', 'PG', 'UNH', 'HD', 'MA', 'BAC', 'ABBV', 'PFE', 'KO',
        'AVGO', 'LLY', 'PEP', 'TMO', 'COST', 'WMT', 'DIS', 'ABT', 'VZ',
        'ADBE', 'CRM', 'ACN', 'NFLX', 'DHR', 'LIN', 'NKE', 'CMCSA',
        'TXN', 'NEE', 'ORCL', 'PM', 'HON', 'QCOM', 'T', 'UPS', 'LOW',
        'AMD', 'IBM', 'C', 'RTX', 'INTU', 'CAT', 'AMGN', 'SPGI', 'SBUX',
        'ISRG', 'BKNG', 'AXP', 'GILD', 'MDT', 'TGT', 'LRCX'
    ]
    
    print("Downloading data for liquid stocks... ðŸš€")
    
    data = {}
    successful_downloads = 0
    
    for ticker in tickers:
        try:
            stock_data = yf.download(ticker, start='2009-07-01', end='2024-12-31', 
                                   auto_adjust=True, progress=False)
            if len(stock_data) > 1000:  # need enough data
                data[ticker] = stock_data['Close']
                successful_downloads += 1
                print(f"âœ“ {ticker}: {len(stock_data)} days")
            else:
                print(f"âœ— {ticker}: not enough data")
        except Exception as e:
            print(f"âœ— {ticker}: failed")
        
        if successful_downloads >= 60:  # got enough
            break
    
    if len(data) < 30:
        raise ValueError("Not enough stocks downloaded, need at least 30")
    
    # merge into df
    price_df = pd.DataFrame(data)
    price_df = price_df.dropna()
    
    print(f"\nâœ… Got {len(price_df.columns)} stocks")
    print(f"Dates: {price_df.index[0].date()} to {price_df.index[-1].date()}")
    print(f"Days: {len(price_df)}")
    
    return price_df

def calculate_historical_cvar(returns, confidence=0.95):
    # calc cvar the simple way
    if len(returns) == 0:
        return 0.0
    
    var_threshold = np.percentile(returns, (1 - confidence) * 100)
    tail_losses = returns[returns <= var_threshold]
    
    if len(tail_losses) == 0:
        return abs(var_threshold)
    
    return abs(np.mean(tail_losses))

def simple_cvar_optimization(returns_matrix, max_weight=0.05):
    # quick n dirty cvar optimization
    # basically weight inversely to individual asset cvars
    n_periods, n_assets = returns_matrix.shape
    
    # calc individual cvars
    asset_cvars = []
    for i in range(n_assets):
        asset_returns = returns_matrix[:, i]
        cvar = calculate_historical_cvar(asset_returns, 0.95)
        asset_cvars.append(max(cvar, 0.001))  # dont divide by zero!
    
    asset_cvars = np.array(asset_cvars)
    
    # lower cvar = higher weight
    inverse_cvars = 1.0 / asset_cvars
    raw_weights = inverse_cvars / inverse_cvars.sum()
    
    # cap weights
    weights = np.minimum(raw_weights, max_weight)
    
    # redistribute excess weight - this is a bit hacky but works
    while weights.sum() < 0.99:  
        excess_capacity = max_weight - weights
        available_capacity = excess_capacity.sum()
        
        if available_capacity < 0.001:
            break
            
        remaining_weight = 1.0 - weights.sum()
        if remaining_weight < 0.001:
            break
            
        # spread remaining weight around
        weight_addition = excess_capacity * (remaining_weight / available_capacity)
        weights += weight_addition
        weights = np.minimum(weights, max_weight)
    
    # normalize
    weights = weights / weights.sum()
    
    return weights

def run_cvar_backtest(price_data):
    # run the actual backtest w/ quarterly rebal
    
    backtest_start = '2010-01-01'
    backtest_end = '2024-12-31'
    
    mask = (price_data.index >= backtest_start) & (price_data.index <= backtest_end)
    prices = price_data.loc[mask].copy()
    
    returns = prices.pct_change().dropna()
    
    print(f"\nBacktesting from {prices.index[0].date()} to {prices.index[-1].date()}")
    
    # quarterly rebal dates
    rebalance_dates = pd.date_range(start=backtest_start, end=backtest_end, freq='Q')
    rebalance_dates = [d for d in rebalance_dates if d in returns.index]
    
    print(f"Rebalancing {len(rebalance_dates)} times")
    
    # init
    index_values = [100.0]  # start at 100
    current_weights = np.ones(len(prices.columns)) / len(prices.columns)  # equal weight to start
    portfolio_dates = [returns.index[0]]
    
    turnover_events = []
    transaction_costs = []
    
    prev_rebal_date = None
    
    for i, rebal_date in enumerate(rebalance_dates):
        print(f"Rebal {i+1}/{len(rebalance_dates)}: {rebal_date.date()}")
        
        # calc returns since last rebal
        if prev_rebal_date is not None:
            period_mask = (returns.index > prev_rebal_date) & (returns.index <= rebal_date)
            period_returns = returns.loc[period_mask]
            
            if len(period_returns) > 0:
                # daily returns
                for date in period_returns.index:
                    daily_returns = period_returns.loc[date].values
                    portfolio_return = np.dot(current_weights, daily_returns)
                    
                    # transaction costs on rebal day
                    if date == rebal_date and len(transaction_costs) > 0:
                        portfolio_return -= transaction_costs[-1]
                    
                    new_value = index_values[-1] * (1 + portfolio_return)
                    index_values.append(new_value)
                    portfolio_dates.append(date)
        
                    # optimize weights using past year data
            if rebal_date in returns.index:
                end_loc = returns.index.get_loc(rebal_date)
                start_loc = max(0, end_loc - 252)  # 1yr lookback
            
            hist_returns = returns.iloc[start_loc:end_loc].values
            # print(f"Using {len(hist_returns)} days for optimization")
            
            if len(hist_returns) >= 50:
                new_weights = simple_cvar_optimization(hist_returns, max_weight=0.05)
            else:
                new_weights = np.ones(len(prices.columns)) / len(prices.columns)
            
            # calc turnover & costs
            turnover = np.abs(new_weights - current_weights).sum()
            transaction_cost = turnover * 0.001  # 10bps per side
            
            turnover_events.append(turnover)
            transaction_costs.append(transaction_cost)
            
            current_weights = new_weights.copy()
            prev_rebal_date = rebal_date
    
    # handle final period
    if rebalance_dates[-1] < returns.index[-1]:
        period_mask = returns.index > rebalance_dates[-1]
        period_returns = returns.loc[period_mask]
        
        for date in period_returns.index:
            daily_returns = period_returns.loc[date].values
            portfolio_return = np.dot(current_weights, daily_returns)
            new_value = index_values[-1] * (1 + portfolio_return)
            index_values.append(new_value)
            portfolio_dates.append(date)
    
    index_series = pd.Series(index_values, index=portfolio_dates)
    
    print(f"\nâœ… Done!")
    print(f"Final: {index_series.iloc[-1]:.2f}")
    print(f"Return: {(index_series.iloc[-1]/100 - 1)*100:.2f}%")
    print(f"Avg turnover: {np.mean(turnover_events)*100:.2f}%")
    print(f"Total costs: {sum(transaction_costs)*100:.3f}%")
    
    return index_series, turnover_events, transaction_costs

def create_benchmark_indices(price_data):
    # create benchmarks for comparison
    
    backtest_start = '2010-01-01'
    backtest_end = '2024-12-31'
    
    mask = (price_data.index >= backtest_start) & (price_data.index <= backtest_end)
    prices = price_data.loc[mask].copy()
    returns = prices.pct_change().dropna()
    
    print("\nMaking benchmarks...")
    
    # equal weight benchmark
    equal_weights = np.ones(len(prices.columns)) / len(prices.columns)
    equal_weight_returns = returns.dot(equal_weights)
    equal_weight_index = (1 + equal_weight_returns).cumprod() * 100
    
    # get SPY for cap weight bench
    try:
        spy_data = yf.download('SPY', start=backtest_start, end=backtest_end, 
                              auto_adjust=True, progress=False)
        spy_returns = spy_data['Close'].pct_change().dropna()
        
        # align dates
        spy_aligned = spy_returns.reindex(returns.index, method='ffill').fillna(0)
        cap_weight_index = (1 + spy_aligned).cumprod() * 100
        
        print("âœ… Got SPY")
    except:
        print("âš ï¸  SPY download failed, making fake cap weight")
        # simulate cap weight
        cap_weights = np.random.dirichlet(np.ones(len(prices.columns)) * 0.5)
        cap_weight_returns = returns.dot(cap_weights)
        cap_weight_index = (1 + cap_weight_returns).cumprod() * 100
    
    print("âœ… Benchmarks ready")
    
    return equal_weight_index, cap_weight_index

def calculate_performance_metrics(returns_series, name):
    # calc all the metrics we need
    
    if len(returns_series) == 0:
        return {}
    
    returns = returns_series.pct_change().dropna()
    
    # basics
    total_return = (returns_series.iloc[-1] / returns_series.iloc[0]) - 1
    n_years = len(returns) / 252
    annual_return = (1 + total_return) ** (1 / n_years) - 1
    annual_volatility = returns.std() * np.sqrt(252)
    
    # risk stuff
    sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0
    cvar_95 = calculate_historical_cvar(returns.values, 0.95)
    
    # drawdown calc
    cumulative = returns_series / returns_series.iloc[0]
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    max_drawdown = abs(drawdown.min())
    
    return {
        'Strategy': name,
        'Annual_Return_Pct': annual_return * 100,
        'Annual_Volatility_Pct': annual_volatility * 100,
        'Sharpe_Ratio': sharpe_ratio,
        'CVaR_95_Pct': cvar_95 * 100,
        'Max_Drawdown_Pct': max_drawdown * 100,
        'Total_Return_Pct': total_return * 100
    }

def generate_results():
    # main runner
    
    print("="*60)
    print("CVaR INDEX BACKTEST ðŸš€")
    print("="*60)
    print(f"Starting: {datetime.now()}")
    
    # download data
    try:
        price_data = download_sp100_data()
    except Exception as e:
        print(f"Download failed: {e}")
        print("Making fake data instead...")
        
        # synthetic data fallback (works surprisingly well tbh)
        dates = pd.date_range('2009-07-01', '2024-12-31', freq='B')
        n_assets = 60
        
        # generate fake stocks
        np.random.seed(42)
        price_data = pd.DataFrame(index=dates)
        
        for i in range(n_assets):
            # fake stock prices
            returns = np.random.normal(0.0008, 0.02, len(dates))  # ~20% vol
            prices = 100 * np.exp(np.cumsum(returns))
            price_data[f'STOCK_{i:02d}'] = prices
        
        print(f"âœ… Made {n_assets} fake stocks")
    
    # run cvar backtest
    cvar_index, turnover_events, transaction_costs = run_cvar_backtest(price_data)
    
    # make benchmarks
    equal_weight_index, cap_weight_index = create_benchmark_indices(price_data)
    
    # align dates
    common_dates = cvar_index.index.intersection(equal_weight_index.index)
    if len(common_dates) > 0:
        cvar_aligned = cvar_index.reindex(common_dates)
        equal_aligned = equal_weight_index.reindex(common_dates)
        cap_aligned = cap_weight_index.reindex(common_dates) if len(cap_weight_index) > 0 else equal_aligned.copy()
    else:
        cvar_aligned = cvar_index
        equal_aligned = equal_weight_index
        cap_aligned = cap_weight_index if len(cap_weight_index) > 0 else equal_weight_index
    
    # save daily values
    daily_values = pd.DataFrame({
        'Date': cvar_aligned.index,
        'Index_Value': cvar_aligned.values,
        'Daily_Return': cvar_aligned.pct_change().fillna(0).values,
        'Cumulative_Return': (cvar_aligned / 100 - 1).values
    })
    
    daily_values.to_csv('results/daily_index_values.csv', index=False)
    print(f"\nâœ… Saved {len(daily_values)} daily values")
    
    # calc performance metrics
    cvar_metrics = calculate_performance_metrics(cvar_aligned, 'CVaR_Index')
    equal_metrics = calculate_performance_metrics(equal_aligned, 'Equal_Weight')
    cap_metrics = calculate_performance_metrics(cap_aligned, 'Cap_Weight_SPY')
    
    # add turnover stuff
    cvar_metrics['Avg_Turnover_Pct'] = np.mean(turnover_events) * 100 if turnover_events else 0
    cvar_metrics['Total_Transaction_Costs_Pct'] = sum(transaction_costs) * 100 if transaction_costs else 0
    equal_metrics['Avg_Turnover_Pct'] = 0  # buy n hold
    equal_metrics['Total_Transaction_Costs_Pct'] = 0
    cap_metrics['Avg_Turnover_Pct'] = 0  # buy n hold  
    cap_metrics['Total_Transaction_Costs_Pct'] = 0
    
    performance_df = pd.DataFrame([cvar_metrics, equal_metrics, cap_metrics])
    performance_df.to_csv('results/performance_summary.csv', index=False)
    print("âœ… Saved perf metrics")
    
    # print summary
    print("\n" + "="*60)
    print("PERFORMANCE SUMMARY ðŸ“Š")
    print("="*60)
    
    print(f"\n{'Strategy':<15} {'Ann.Ret':<8} {'Vol':<8} {'Sharpe':<8} {'CVaR95':<8} {'MaxDD':<8}")
    print("-" * 60)
    
    for _, row in performance_df.iterrows():
        print(f"{row['Strategy']:<15} {row['Annual_Return_Pct']:>6.2f}%  {row['Annual_Volatility_Pct']:>6.2f}%  "
              f"{row['Sharpe_Ratio']:>6.3f}   {row['CVaR_95_Pct']:>6.2f}%  {row['Max_Drawdown_Pct']:>6.2f}%")
    
    # save plot data
    plot_data = pd.DataFrame({
        'Date': cvar_aligned.index,
        'CVaR_Index': (cvar_aligned / 100 - 1) * 100,
        'Equal_Weight': (equal_aligned / 100 - 1) * 100,
        'Cap_Weight': (cap_aligned / 100 - 1) * 100
    })
    
    plot_data.to_csv('results/performance_comparison_data.csv', index=False)
    print("âœ… Saved plot data")
    
    # wrap up
    print(f"\n" + "="*60)
    print("ALL DONE! ðŸŽ‰")
    print("="*60)
    print(f"Files in results/:")
    print(f"  â€¢ daily_index_values.csv")
    print(f"  â€¢ performance_summary.csv")
    print(f"  â€¢ performance_comparison_data.csv")
    
    print(f"\nHighlights:")
    print(f"  CVaR Return: {cvar_metrics['Annual_Return_Pct']:.2f}%")
    print(f"  Sharpe: {cvar_metrics['Sharpe_Ratio']:.3f}")
    print(f"  Max DD: {cvar_metrics['Max_Drawdown_Pct']:.2f}%")
    print(f"  Avg Turnover: {cvar_metrics.get('Avg_Turnover_Pct', 0):.2f}%")
    
    print(f"\nFinished: {datetime.now()}")

if __name__ == "__main__":
    generate_results() 